---
format: 
    revealjs:
        slide-number: false
        theme: [default, style.scss]
        footer: "[https://www.BedeFfinianRoweDavies.com](www.bedeffinianrowedavies.com)"
        logo: Data/Input/Stats.png
        width: 2400
        height: 1350
---
##

::: {style="position: absolute; left: 500px; top: 10px; height: 200px; width: 1650px; background-color: #abdbe3; padding: 20px; padding-left: 50px;"}
[A Practical Introduction to Regression with (General/Generalised) Linear Models.]{style="font-size: 90px; font-weight: bold; line-height: 1em; margin: 0px"}

:::

::: {style="position: absolute; left: 500px; bottom: 1%; height: 150px; width: 520px; background-color: #abdbe3; padding: 20px; padding-left: 50px;"}

[Bede Ffinian Rowe Davies]{style="font-size: 45px; font-weight: bold;"}

[Post-Doctoral Researcher]{style="font-size: 40px; font-weight: bold;"}

:::: 


::: {style="position: absolute; left: 1500px; bottom: 1%; height: 150px; width: 520px; background-color: #abdbe3; padding: 20px; padding-left: 50px;"}

[University of Nantes]{style="font-size: 45px; font-weight: bold;"}

[Spring Semester 2023]{style="font-size: 40px; font-weight: bold;"}

:::: 


::: {.absolute bottom="14%" left="28%"}
![](Data/Input/Example_Plot.png){height="850"}
:::


```{r Gauss}
#| warning: false
#| echo: false
#| results: hide


library(Utilities.Package)
library(tidyverse)

n=50
a=2
b=2
xGaus=seq(1,100,length.out=n)
yGaus=a+b*xGaus
o=10
uGaus=rnorm(n,mean = yGaus,sd=o)

p1<-data.frame(y=yGaus,u=uGaus,x=xGaus) %>% 
ggplot()+
  geom_line(aes(x=x,y=y),linewidth=2,colour="darkcyan",alpha=0.7)+
  geom_point(aes(x=x,y=u),size=2,colour="grey50")+
  theme_Bede()

p2<-data.frame(y=yGaus,u=uGaus,x=xGaus) %>% 
ggplot()+
  geom_line(aes(x=x,y=y),linewidth=2,colour="darkcyan",alpha=0.7)+
  geom_segment(aes(x=x,xend=x,y=y,yend=u),colour="red")+
  geom_point(aes(x=x,y=u),size=2,colour="grey50")+
  theme_Bede()

ResidualsGaus<-data.frame(y=yGaus,u=uGaus,x=xGaus) %>% 
  dplyr::mutate(Residuals=(u-y)/sqrt(y))%>% 
  ggplot()+
  geom_point(aes(x=y,y=Residuals),colour="red",alpha=0.7)+
    labs(x="Fitted Values",y="Residuals")+
  theme_Bede()

```

## Overview {style="font-size: 60px; font-weight: bold;"}


::: {.absolute top="0" left="95%"}
::: {.sectionhead}
1 [2 3 4 5 6]{style="opacity:0.25"}
:::
:::

::: {.incremental}

- [Response Variable Data Types]{style="font-size: 50px;"}

    - [Continuous? Integers? Positive? Contain Zeros?]{style="font-size: 40px;" }
    
- [What is a General Linear Model (GLM)?]{style="font-size: 50px;"}

    - [allow the prediction of a response variable by independent variable(s)]{style="font-size: 40px;" }
    
    - [Equivalent to Correlation, t-tests, ANOVA, ANCOVA etc.]{style="font-size: 40px;" }

- [What is a GLM?]{style="font-size: 50px;"}

    - [Higher Flexibilty When Understood]{style="font-size: 40px;"}

    - [Can Model Complex Relationships]{style="font-size: 40px;"}

    - [Can be used for Prediction or Description (or both)]{style="font-size: 40px;"}

- [When to Use a GLM?]{style="font-size: 50px;"}

    - [Assess Relationships Between Different Data Types]{style="font-size: 40px;"}

:::

## Data Types {style="font-size: 60px; font-weight: bold;"}


::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1]{style="opacity:0.25"} 2 [3 4 5 6]{style="opacity:0.25"}
:::
:::

::: {.incremental}

- [Response Data Types (Independent Variable):]{style="font-size: 50px;left: 500px;"}

    - [Continuous and All Real Numbers: Gaussian (Normal)]{style="font-size: 40px;"}

    - [Continuous and All Positive Values: Gamma]{style="font-size: 40px;"}
    
    - [Continuous and Bound Between Range: Beta]{style="font-size: 40px;"}

    - [Discrete and all Non-Negative Values: Poisson]{style="font-size: 40px;"}
   
    - [Discrete and Set Upper Bound Values: Binomial]{style="font-size: 40px;"}

- [Predictor/Fixed Effects (Dependent Variables):]{style="font-size: 50px;"}

    - [Continuous]{style="font-size: 40px;"}

    - [Factors/Groups]{style="font-size: 40px;"}

    - [Combinations of Above]{style="font-size: 40px;"}

:::


## Continuous and All Real Numbers: Gaussian {style="font-size: 60px; font-weight: bold;"}

### Linear Model {style="font-size: 60px; font-weight: bold;"}


::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2]{style="opacity:0.25"} 3 [4 5 6]{style="opacity:0.25"}
:::
:::


:::: {.columns}
::: {.column width="40%"}
$y = Normal(\mu,\sigma)$

$\mu = \alpha + \beta_{1}x + \epsilon$

$y = Normal(\alpha + \beta_{1}x,\sigma)$
:::

::: {.column width="60%"}
$y$ normal distribution with mean $\mu$ and SD $\sigma$

$\alpha$ is the intercept when $\beta_{1}x = 0$ 

$\beta_{1}$ is the slope of the line
:::
::::

```{r}
#| echo: false
#| fig-height: 4
#| fig-align: "center"
p1
```

## Continuous and All Real Numbers: Gaussian {style="font-size: 60px; font-weight: bold;"}

### Linear Model {style="font-size: 60px; font-weight: bold;"}


::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2]{style="opacity:0.25"} 3 [4 5 6]{style="opacity:0.25"}
:::
:::


:::: {.columns}
::: {.column width="40%"}
$y = Normal(\mu,\sigma)$

$\mu = \alpha + \beta_{1}x + \epsilon$

$y = Normal(\alpha + \beta_{1}x,\sigma)$

:::

::: {.column width="60%"}
$\beta$ and $\alpha$ are estimated by minimising error: $\epsilon$

Maximum Likelihood (ML) using Least Squares

ML minimises the cummulative error ($\epsilon$)
:::
::::

```{r}
#| echo: false
#| fig-height: 4
#| fig-align: "center"
p2
```

## Discrete and Non-Negative Numbers: Poisson {style="font-size: 60px; font-weight: bold;"}

### General (Still) Linear Model {style="font-size: 60px; font-weight: bold;"}

```{r Pois}
#| warning: false
#| echo: false
#| results: hide


library(Utilities.Package)
library(tidyverse)

n=100
a=2
b=0.04
xPois = runif(100, min = 0, max = 100)
y1=a+b*xPois
yPois=exp(y1)
uPois<-rpois(n,lambda=yPois)

pois1<-data.frame(y=yPois,u=uPois,x=xPois) %>% 
ggplot()+
  geom_line(aes(x=x,y=y),linewidth=2,colour="darkcyan",alpha=0.7)+
  geom_point(aes(x=x,y=u),size=2,colour="grey50")+
  theme_Bede()

pois2<-data.frame(y=yPois,u=uPois,x=xPois) %>% 
ggplot()+
  geom_line(aes(x=x,y=log(y)),linewidth=2,colour="darkcyan",alpha=0.7)+
  geom_point(aes(x=x,y=log(u)),size=2,colour="grey50")+
  geom_segment(aes(x=x,xend=x,y=log(y),yend=log(u)),colour="red")+
  theme_Bede()

ResidualsPois<-data.frame(y=yPois,u=uPois,x=xPois) %>% 
  dplyr::mutate(Residuals=(u-y)/sqrt(y))%>% 
  ggplot()+
  geom_point(aes(x=y,y=Residuals),colour="red",alpha=0.7)+
  labs(x="Fitted Values",y="Residuals")+
  theme_Bede()


```

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3]{style="opacity:0.25"} 4 [5 6]{style="opacity:0.25"}
:::
:::

:::: {.columns}
::: {.column width="40%"}
$y = Poisson(\lambda)$

$\lambda = log(\mu)$

$\mu = \alpha + \beta_{1}x + \epsilon$

$y = Poisson(log(\alpha + \beta_{1}x))$
:::

::: {.column width="60%"}
$y$ poisson distribution with mean $\lambda$

$log(\mu)$ is "log-link" between linear exquation and $y$

$\alpha$ is the intercept when $\beta_{1}x = 0$ 

$\beta_{1}$ is the slope of the line
:::
::::

```{r}
#| echo: false
#| fig-height: 4
#| fig-align: "center"
pois1
```

## Discrete and Non-Negative Numbers: Poisson {style="font-size: 60px; font-weight: bold;"}

### General (Still) Linear Model {style="font-size: 60px; font-weight: bold;"}


::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3]{style="opacity:0.25"} 4 [5 6]{style="opacity:0.25"}
:::
:::

:::: {.columns}
::: {.column width="40%"}
$y = Poisson(\lambda)$

$\lambda = log(\mu)$

$\mu = \alpha + \beta_{1}x + \epsilon$

$y = Poisson(log(\alpha + \beta_{1}x))$
:::

::: {.column width="60%"}
ML used to minimise $\epsilon$

$log(\mu)$ is "log-link" between linear equation and $y$

$\beta_{1}$ is the slope of the line
:::
::::

```{r}
#| echo: false
#| fig-height: 4
#| fig-align: "center"
pois2
```


## Discrete and Set Values: Binomial {style="font-size: 60px; font-weight: bold;"}

### General (Still) Linear Model {style="font-size: 60px; font-weight: bold;"}

```{r Binom}
#| warning: false
#| echo: false
#| results: hide

library(Utilities.Package)
library(tidyverse)

n<-100
a<-1
b<-1
xbinom<- seq(-4,4, length.out = 100)
y1<-a+b*xbinom
ybinom<-exp(y1)/(1+exp(y1))
ubinom<-rbinom(n,1,ybinom)

binom1<-data.frame(y=ybinom,u=ubinom,x=xbinom) %>% 
ggplot()+
  geom_line(aes(x=x,y=y),linewidth=2,colour="darkcyan",alpha=0.7)+
  geom_point(aes(x=x,y=u),size=2,colour="grey50")+
  theme_Bede()



binom2<-data.frame(y=ybinom,u=ubinom,x=xbinom) %>% 
ggplot()+
  geom_line(aes(x=x,y=y1),linewidth=2,colour="darkcyan",alpha=0.7)+
  geom_point(aes(x=x,y=y),size=2,colour="grey50")+
  geom_segment(aes(x=x,xend=x,y=y1,yend=y),colour="red")+
  theme_Bede()


```

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5 [6]{style="opacity:0.25"}
:::
:::

:::: {.columns}
::: {.column width="40%"}
$y = Binomial(Pr)$

$Pr = logit(\mu)$

$\mu = \alpha + \beta_{1}x + \epsilon$

$y = Binomial(logit(\alpha + \beta_{1}x))$
:::

::: {.column width="60%"}
$y$ poisson distribution with mean $\lambda$

$log(\mu)$ is "log-link" between linear equation and $y$

$\alpha$ is the intercept when $\beta_{1}x = 0$ 

$\beta_{1}$ is the slope of the line
:::
::::

```{r}
#| echo: false
#| fig-height: 4
#| fig-align: "center"
binom1
```

## Discrete and Set Values: Binomial {style="font-size: 60px; font-weight: bold;"}

### General (Still) Linear Model {style="font-size: 60px; font-weight: bold;"}


::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5 [6]{style="opacity:0.25"}
:::
:::

:::: {.columns}
::: {.column width="40%"}
$y = Binomial(Pr)$

$Pr = logit(\mu)$

$\mu = \alpha + \beta_{1}x + \epsilon$

$y = Binomial(logit(\alpha + \beta_{1}x))$
:::

::: {.column width="60%"}
Maximum Likelihood (ML) used to minimise $\epsilon$

$logit(\mu)$ is "logit-link" between linear exquation and $y$

$\beta_{1}$ is the slope of the line
:::
::::

```{r}
#| echo: false
#| fig-height: 4
#| fig-align: "center"
binom2
```

## What Are Residuals? {style="font-size: 60px; font-weight: bold;"}

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4 5]{style="opacity:0.25"} 6
:::
:::

```{r}
#| echo: false
#| fig-height: 6
#| fig-width: 12
#| fig-align: "center"
library(patchwork)

(p2+ResidualsGaus)/(pois2+ResidualsPois)+
  plot_annotation(tag_levels=list(c("Gaussian","Gaussian","Poisson","Poisson")))& 
  theme(plot.tag.position = c(0.3, 0.95))
```

## Assumptions {style="font-size: 60px; font-weight: bold;"}

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4 5]{style="opacity:0.25"} 6
:::
:::

::: {.incremental}

- [Gaussian]{style="font-size: 50px;"}

    - [Linear Relationship between $x$ and $y$]{style="font-size: 40px;" }
        
    - [Independence of Samples]{style="font-size: 40px;" }

    - [Homoscedasticity of Residuals]{style="font-size: 40px;" }

    - [Normality of Residuals]{style="font-size: 40px;" }

- [Poisson]{style="font-size: 50px;"}

    - [allow the prediction of a response variable by independent variable(s)]{style="font-size: 40px;" }
    
    - [Equivalent to Correlation, t-tests, ANOVA, ANCOVA etc.]{style="font-size: 40px;" }

- [Binomial]{style="font-size: 50px;"}

    - [Higher Flexibilty When Understood]{style="font-size: 40px;"}

    - [Can Model Complex Relationships]{style="font-size: 40px;"}

    - [Can be used for Prediction or Description (or both)]{style="font-size: 40px;"}

:::



